{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"] = os.path.join(os.getcwd(), \"venv\", \"Scripts\", \"python.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Churn Prediction\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb+srv://nguyenminhy7714:minhy112@cluster0.xxkrzas.mongodb.net/telco_churn\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb+srv://nguyenminhy7714:minhy112@cluster0.xxkrzas.mongodb.net/telco_churn\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Kết nối MongoDB bằng pymongo\n",
    "client = MongoClient(\"mongodb+srv://nguyenminhy7714:minhy112@cluster0.xxkrzas.mongodb.net\")\n",
    "db = client[\"telco_churn\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Lấy dữ liệu từ các collection và gộp bằng Aggregation Pipeline\u001b[39;00m\n\u001b[32m      2\u001b[39m pipeline = [\n\u001b[32m      3\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33m$lookup\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mfrom\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcontract_info\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlocalField\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcustomerID\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mforeignField\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcustomerID\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mas\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcontract\u001b[39m\u001b[33m\"\u001b[39m}},\n\u001b[32m      4\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33m$lookup\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mfrom\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33minternet_service\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlocalField\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcustomerID\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mforeignField\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mcustomerID\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mas\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33minternet\u001b[39m\u001b[33m\"\u001b[39m}},\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     }}\n\u001b[32m     13\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m data = \u001b[38;5;28mlist\u001b[39m(\u001b[43mdb\u001b[49m.churn_info.aggregate(pipeline))\n\u001b[32m     16\u001b[39m df_pandas = pd.DataFrame(data)\n\u001b[32m     17\u001b[39m df_pandas = df_pandas.drop(\u001b[33m\"\u001b[39m\u001b[33m_id\u001b[39m\u001b[33m\"\u001b[39m, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "# Lấy dữ liệu từ các collection và gộp bằng Aggregation Pipeline\n",
    "pipeline = [\n",
    "    {\"$lookup\": {\"from\": \"contract_info\", \"localField\": \"customerID\", \"foreignField\": \"customerID\", \"as\": \"contract\"}},\n",
    "    {\"$lookup\": {\"from\": \"internet_service\", \"localField\": \"customerID\", \"foreignField\": \"customerID\", \"as\": \"internet\"}},\n",
    "    {\"$unwind\": \"$contract\"},\n",
    "    {\"$unwind\": \"$internet\"},\n",
    "    {\"$project\": {\n",
    "        \"customerID\": 1,\n",
    "        \"PaymentMethod\": \"$contract.PaymentMethod\",\n",
    "        \"InternetService\": \"$internet.InternetService\",\n",
    "        \"Churn\": 1\n",
    "    }}\n",
    "]\n",
    "\n",
    "data = list(db.churn_info.aggregate(pipeline))\n",
    "df_pandas = pd.DataFrame(data)\n",
    "df_pandas = df_pandas.drop(\"_id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>Churn</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>InternetService</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>No</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>DSL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>DSL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>DSL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>DSL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>Fiber optic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID Churn              PaymentMethod InternetService\n",
       "0  7590-VHVEG    No           Electronic check             DSL\n",
       "1  5575-GNVDE    No               Mailed check             DSL\n",
       "2  3668-QPYBK   Yes               Mailed check             DSL\n",
       "3  7795-CFOCW    No  Bank transfer (automatic)             DSL\n",
       "4  9237-HQITU   Yes           Electronic check     Fiber optic"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển sang PySpark DataFrame\n",
    "df = spark.createDataFrame(df_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customerID: string (nullable = true)\n",
      " |-- Churn: string (nullable = true)\n",
      " |-- PaymentMethod: string (nullable = true)\n",
      " |-- InternetService: string (nullable = true)\n",
      "\n",
      "+----------+-----+--------------------+---------------+\n",
      "|customerID|Churn|       PaymentMethod|InternetService|\n",
      "+----------+-----+--------------------+---------------+\n",
      "|7590-VHVEG|   No|    Electronic check|            DSL|\n",
      "|5575-GNVDE|   No|        Mailed check|            DSL|\n",
      "|3668-QPYBK|  Yes|        Mailed check|            DSL|\n",
      "|7795-CFOCW|   No|Bank transfer (au...|            DSL|\n",
      "|9237-HQITU|  Yes|    Electronic check|    Fiber optic|\n",
      "+----------+-----+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi dữ liệu phân loại\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=\"PaymentMethod\", outputCol=\"PaymentMethodIdx\"),\n",
    "    StringIndexer(inputCol=\"InternetService\", outputCol=\"InternetServiceIdx\"),\n",
    "    StringIndexer(inputCol=\"Churn\", outputCol=\"ChurnIdx\")\n",
    "]\n",
    "\n",
    "for indexer in indexers:\n",
    "    df = indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding\n",
    "encoders = [\n",
    "    OneHotEncoder(inputCols=[\"PaymentMethodIdx\"], outputCols=[\"PaymentMethodVec\"]),\n",
    "    OneHotEncoder(inputCols=[\"InternetServiceIdx\"], outputCols=[\"InternetServiceVec\"])\n",
    "]\n",
    "\n",
    "for encoder in encoders:\n",
    "    df = encoder.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo vector đặc trưng\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"PaymentMethodVec\", \"InternetServiceVec\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "df = assembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "df = scaler.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm chuyển đổi array thành VectorUDT\n",
    "array_to_vector = udf(lambda x: Vectors.dense(x), VectorUDT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xử lý mất cân bằng dữ liệu (nếu cần)\n",
    "# Chuyển về Pandas để dùng SMOTE\n",
    "pandas_df = df.select(\"scaledFeatures\", \"ChurnIdx\").toPandas()\n",
    "X = pandas_df[\"scaledFeatures\"].apply(lambda x: x.toArray()).tolist()\n",
    "y = pandas_df[\"ChurnIdx\"]\n",
    "\n",
    "smote = SMOTE()\n",
    "X_res, y_res = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển lại thành PySpark DataFrame\n",
    "resampled_pd = pd.DataFrame({\"features\": list(X_res), \"label\": y_res})\n",
    "resampled_df = spark.createDataFrame(resampled_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển cột features từ ArrayType sang VectorUDT\n",
    "resampled_df = resampled_df.withColumn(\"features\", array_to_vector(\"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.sql.functions import col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia dữ liệu\n",
    "train_data, test_data = resampled_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huấn luyện mô hình Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    numTrees=100,\n",
    "    maxDepth=10,\n",
    "    featureSubsetStrategy=\"auto\"\n",
    ")\n",
    "rf_model = rf.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mô hình đã được lưu tại: rf_churn_model\n"
     ]
    }
   ],
   "source": [
    "# Lưu mô hình vào đĩa\n",
    "model_path = \"rf_churn_model\"\n",
    "rf_model.write().overwrite().save(model_path)\n",
    "print(f\"Mô hình đã được lưu tại: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển train_data từ PySpark DataFrame sang Pandas DataFrame\n",
    "train_pandas = train_data.toPandas()\n",
    "\n",
    "# Tách X_train (đặc trưng) và y_train (nhãn)\n",
    "X_train = train_pandas[\"features\"].apply(lambda x: x.toArray()).tolist()  # Chuyển Vector thành list\n",
    "y_train = train_pandas[\"label\"].tolist()  # Nhãn đã ở dạng số (0 hoặc 1)\n",
    "\n",
    "# Tương tự với test_data (nếu cần)\n",
    "test_pandas = test_data.toPandas()\n",
    "X_test = test_pandas[\"features\"].apply(lambda x: x.toArray()).tolist()\n",
    "y_test = test_pandas[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8290, 5)\n",
      "y_train shape: (8290,)\n",
      "X_test shape: (2058, 5)\n",
      "y_test shape: (2058,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Chuyển X_train và y_train thành mảng NumPy\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Tương tự với X_test và y_test\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Kiểm tra kích thước\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_model.pkl']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Lưu mô hình\n",
    "joblib.dump(model, \"rf_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập kiểm tra\n",
    "predictions = rf_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi kết quả dự đoán về nhãn Yes/No\n",
    "predictions = predictions.withColumn(\n",
    "    \"Churn_Predicted\",\n",
    "    when(col(\"prediction\") == 0, \"No\").otherwise(\"Yes\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.684645286686103\n",
      "Precision: 0.6995299658651501\n",
      "Recall: 0.684645286686103\n",
      "F1-Score: 0.6802746515246025\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá các chỉ số\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[595. 457.]\n",
      " [192. 814.]]\n"
     ]
    }
   ],
   "source": [
    "# Tính Confusion Matrix và Classification Report\n",
    "# Chuyển đổi predictions thành RDD để sử dụng MulticlassMetrics\n",
    "prediction_and_labels = predictions.select(\"prediction\", \"label\") \\\n",
    "    .rdd.map(lambda row: (float(row[\"prediction\"]), float(row[\"label\"])))\n",
    "\n",
    "# Khởi tạo MulticlassMetrics\n",
    "metrics = MulticlassMetrics(prediction_and_labels)\n",
    "\n",
    "# In Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "Class\tPrecision\tRecall\t\tF1-Score\n",
      "0.0\t0.7560\t\t0.5656\t\t0.6471\n",
      "1.0\t0.6404\t\t0.8091\t\t0.7150\n",
      "\n",
      "Support: Class 0 (No): 1052, Class 1 (Yes): 1006\n"
     ]
    }
   ],
   "source": [
    "# Tính toán thủ công các chỉ số cho từng lớp (classification report)\n",
    "labels = [0.0, 1.0]  # Các nhãn: 0 (No), 1 (Yes)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"Class\\tPrecision\\tRecall\\t\\tF1-Score\")\n",
    "for label in labels:\n",
    "    precision = metrics.precision(label)\n",
    "    recall = metrics.recall(label)\n",
    "    f1 = metrics.fMeasure(label)\n",
    "    print(f\"{label}\\t{precision:.4f}\\t\\t{recall:.4f}\\t\\t{f1:.4f}\")\n",
    "\n",
    "# Tổng số mẫu trong từng lớp (support)\n",
    "support_0 = predictions.filter(col(\"label\") == 0).count()\n",
    "support_1 = predictions.filter(col(\"label\") == 1).count()\n",
    "print(f\"\\nSupport: Class 0 (No): {support_0}, Class 1 (Yes): {support_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
